{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"data_banknote_authentication.txt\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "X = []\n",
    "Y = []\n",
    "for i in r:\n",
    "    x = i.split(',')\n",
    "    for j in range(0,len(x)-1):\n",
    "        try:\n",
    "            x[j] = float(x[j])\n",
    "        except ValueError:\n",
    "            x[j] = 0.0\n",
    "    X.append(map(float,x[0:len(x)-1]))\n",
    "    Y.append([int(x[-1])])\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(data):\n",
    "    z = data\n",
    "    for j in z:\n",
    "        j.insert(0,1)   \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i[0] not in class_count1.keys():\n",
    "            class_count1[i[0]] = 1\n",
    "        else:\n",
    "            class_count1[i[0]] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_high_dimension(Data,degree):\n",
    "    polyfeat_object = PolynomialFeatures(degree)\n",
    "    hd_data = polyfeat_object.fit_transform(Data)\n",
    "    return hd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate_data(data,labels,clabels):\n",
    "    multi_X = {}\n",
    "    for i in range(len(clabels)):\n",
    "        if clabels[i] not in multi_X.keys():\n",
    "            multi_X[clabels[i]] = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j][0] == clabels[i]:\n",
    "                multi_X[clabels[i]].append(data[j]) \n",
    "    for i in multi_X:\n",
    "        multi_X[i] = np.array(multi_X[i])\n",
    "    return multi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sigmoid(theta,data):\n",
    "    sigmoid = []\n",
    "    for i in data:\n",
    "        x = np.dot(theta.transpose(),i)\n",
    "        sigmoid.append([1.0/(1+np.exp(-x))])\n",
    "    return np.array(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta_assume, learning_rate, interation_count):\n",
    "    theta = np.ones(len(x[0]))\n",
    "    theta.fill(theta_assume)\n",
    "    for i in range(interation_count):\n",
    "        h = find_sigmoid(theta,x)\n",
    "        new = learning_rate*(np.sum((h-y)*x,axis = 0))\n",
    "        theta = theta - new\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(theta,data):\n",
    "    sigmoid = find_sigmoid(theta,data)\n",
    "    predict = []\n",
    "    for i in sigmoid:\n",
    "        if i[0] > 0.5:\n",
    "            predict.append([1])\n",
    "        elif i[0] < 0.5:\n",
    "            predict.append([0])\n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squrae_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j][0] == i and actual[j][0] == predicted[j][0]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j][0] == i and actual[j][0] != predicted[j][0]:\n",
    "                tmp[clabels.index(predicted[j][0])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    precision = find_precision(confmatrix)\n",
    "    recall = find_recall(confmatrix)\n",
    "    return precision,recall,confmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,clabels, n_folds=10,MSE = False):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    accuracies = []\n",
    "    precision_list = []\n",
    "    confusion = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_theta = gradient_descent(data[train_ind], labels[train_ind],0.0001,0.0001,300)\n",
    "        training_MSE = mean_squrae_error(prediction(train_theta,data[train_ind]), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(train_theta,data[test_ind])\n",
    "        p,r,cm = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        confusion.append(cm)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "        accuracies.append(accuracy_score(labels[test_ind], predict))\n",
    "        \n",
    "    if MSE == True:\n",
    "        for i in range(len(testing_MSE_list)):\n",
    "            print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "        print \"Average Mean Square Error\"\n",
    "        print \"Training Error \\t Testing Error\"\n",
    "        print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    else:\n",
    "        for i in range(len(accuracies)):\n",
    "            print 'Fold',i,'Accuracy',accuracies[i]\n",
    "        print \"Average Accuracy \", np.mean(accuracies)\n",
    "    return precision_list,recall_list,training_MSE_list,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(theta,data):\n",
    "    soft = {}\n",
    "    for i in data:\n",
    "        s = 0\n",
    "        for j in theta:\n",
    "            s = s + np.exp(np.dot(theta[j].transpose(),i))\n",
    "        for k in theta:\n",
    "            x = np.exp(np.dot(theta[k].transpose(),i))\n",
    "            if k not in soft.keys():\n",
    "                soft[k] = [[(x*1.0)/s]]\n",
    "            else:\n",
    "                soft[k].append([(x*1.0)/s])\n",
    "    return soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indicator(y,cl):\n",
    "    ind = {}\n",
    "    for k in cl:\n",
    "        for l in y:\n",
    "            if l[0] == k:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[1]]\n",
    "                else:\n",
    "                    ind[k].append([1])\n",
    "            else:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[0]]\n",
    "                else:\n",
    "                    ind[k].append([0])\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_soft(x, y, theta_assume, learning_rate, interation_count,classes):\n",
    "    thetas = {}\n",
    "    theta = np.ones(len(x[0]))\n",
    "    theta.fill(theta_assume)\n",
    "    for i in classes:\n",
    "        thetas[i] = theta\n",
    "    indicators = indicator(y,classes)\n",
    "    for i in range(interation_count):\n",
    "        h = softmax(thetas,x)\n",
    "        for j in h:\n",
    "            new = learning_rate*(np.sum((np.array(h[i])-np.array(indicators[i]))*x,axis = 0))\n",
    "            thetas[i] = thetas[i] - new\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_kclass(theta,data,cl):\n",
    "    pred = []\n",
    "    predi = []\n",
    "    for i in data:\n",
    "        tmp = []\n",
    "        for j in theta:\n",
    "            tmp.append((j,np.dot(theta[j].transpose(),i)))\n",
    "        pred.append(tmp)\n",
    "    for i in pred:\n",
    "        predi.append([max(i,key=lambda item:item[1])[0]])\n",
    "    return predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_kclass(data, labels,clabels, n_folds=10):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    precision_list = []\n",
    "    confusion = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_theta = gradient_descent_soft(data[train_ind], labels[train_ind],0.0000001,0.0001,300,clabels)\n",
    "        training_MSE = mean_squrae_error(predict_kclass(train_theta,data[train_ind],clabels), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = predict_kclass(train_theta,data[test_ind],clabels)\n",
    "        p,r,cm = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        confusion.append(cm)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "    for i in range(len(testing_MSE_list)):\n",
    "        print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "    print \"Average Mean Square Error\"\n",
    "    print \"Training Error \\t Testing Error\"\n",
    "    print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    return precision_list,recall_list,training_MSE_list,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z= deepcopy(X)\n",
    "Z = create_data(Z)\n",
    "Z = np.array(Z)\n",
    "X = np.array(X)\n",
    "classes,class_count,alpha = find_alpha(Y)\n",
    "Z_split =segregate_data(Z,Y,classes)\n",
    "X_split = segregate_data(X,Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value \t True Value \n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n",
      "[0] \t\t\t[0]\n"
     ]
    }
   ],
   "source": [
    "logistic_theta = gradient_descent(X,Y,0.01,0.001,300)\n",
    "predictions = prediction(logistic_theta,X)\n",
    "print \"Predicted Value \\t True Value \"\n",
    "for i in range(11,21):\n",
    "    print predictions[i],\"\\t\\t\\t\",Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.68534191 -1.64560428 -1.74869086 -0.82080437]\n"
     ]
    }
   ],
   "source": [
    "print logistic_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy 0.927536231884\n",
      "Fold 1 Accuracy 0.920289855072\n",
      "Fold 2 Accuracy 0.905109489051\n",
      "Fold 3 Accuracy 0.912408759124\n",
      "Fold 4 Accuracy 0.963503649635\n",
      "Fold 5 Accuracy 0.890510948905\n",
      "Fold 6 Accuracy 0.941605839416\n",
      "Fold 7 Accuracy 0.897810218978\n",
      "Fold 8 Accuracy 0.941605839416\n",
      "Fold 9 Accuracy 0.978102189781\n",
      "Average Accuracy  0.927848302126\n"
     ]
    }
   ],
   "source": [
    "pre_roc, recall_roc,test_error,conf_mat = cross_validation(X, Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.06401945]\n",
      "Fold 1 Testing Error [ 0.05996759]\n",
      "Fold 2 Testing Error [ 0.06072874]\n",
      "Fold 3 Testing Error [ 0.06072874]\n",
      "Fold 4 Testing Error [ 0.06477733]\n",
      "Fold 5 Testing Error [ 0.05910931]\n",
      "Fold 6 Testing Error [ 0.07287449]\n",
      "Fold 7 Testing Error [ 0.06963563]\n",
      "Fold 8 Testing Error [ 0.06558704]\n",
      "Fold 9 Testing Error [ 0.06882591]\n",
      "Average Mean Square Error\n",
      "0.0646254240513\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_error)):\n",
    "        print 'Fold',i,'Testing Error',test_error[i]\n",
    "print \"Average Mean Square Error\"\n",
    "print np.mean(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy 0.985507246377\n",
      "Fold 1 Accuracy 0.985507246377\n",
      "Fold 2 Accuracy 0.985401459854\n",
      "Fold 3 Accuracy 0.978102189781\n",
      "Fold 4 Accuracy 0.992700729927\n",
      "Fold 5 Accuracy 0.992700729927\n",
      "Fold 6 Accuracy 0.992700729927\n",
      "Fold 7 Accuracy 0.963503649635\n",
      "Fold 8 Accuracy 0.978102189781\n",
      "Fold 9 Accuracy 0.978102189781\n",
      "Average Accuracy  0.983232836137\n"
     ]
    }
   ],
   "source": [
    "logistic_thetaz = gradient_descent(Z,Y,0.01,0.001,300)\n",
    "predictions_z = prediction(logistic_thetaz,Z)\n",
    "pre_rocz, recall_rocz,test_errorz,conf_matz = cross_validation(Z, Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.01863857]\n",
      "Fold 1 Testing Error [ 0.01134522]\n",
      "Fold 2 Testing Error [ 0.0194332]\n",
      "Fold 3 Testing Error [ 0.01214575]\n",
      "Fold 4 Testing Error [ 0.02024291]\n",
      "Fold 5 Testing Error [ 0.01214575]\n",
      "Fold 6 Testing Error [ 0.02024291]\n",
      "Fold 7 Testing Error [ 0.01214575]\n",
      "Fold 8 Testing Error [ 0.01781377]\n",
      "Fold 9 Testing Error [ 0.0194332]\n",
      "Average Mean Square Error\n",
      "0.0163587031411\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_errorz)):\n",
    "        print 'Fold',i,'Testing Error',test_errorz[i]\n",
    "print \"Average Mean Square Error\"\n",
    "print np.mean(test_errorz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[752  10]\n",
      " [  3 607]]\n",
      "Accuracy 0.990524781341\n",
      "Precision [0.99602649006622512, 0.98379254457050247]\n",
      "Recall [0.98687664041994749, 0.9950819672131147]\n",
      "F_score [0.99143045484508896, 0.98940505297473513]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,Y,predictions_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_hd = map_high_dimension(X,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy 0.992753623188\n",
      "Fold 1 Accuracy 1.0\n",
      "Fold 2 Accuracy 1.0\n",
      "Fold 3 Accuracy 0.992700729927\n",
      "Fold 4 Accuracy 0.992700729927\n",
      "Fold 5 Accuracy 0.992700729927\n",
      "Fold 6 Accuracy 1.0\n",
      "Fold 7 Accuracy 1.0\n",
      "Fold 8 Accuracy 0.992700729927\n",
      "Fold 9 Accuracy 0.992700729927\n",
      "Average Accuracy  0.995625727282\n"
     ]
    }
   ],
   "source": [
    "logistic_theta_poly = gradient_descent(X_hd,Y,0.0001,0.0001,300)\n",
    "predictions_poly = prediction(logistic_theta_poly,X_hd)\n",
    "pre_rocp, recall_rocp,test_errorp,conf_matp = cross_validation(X_hd, Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Mean Square Error\n",
      "0.0034012690372\n"
     ]
    }
   ],
   "source": [
    "print \"Average Mean Square Error\"\n",
    "print np.mean(test_errorp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[762   0]\n",
      " [  8 602]]\n",
      "Accuracy 0.99416909621\n",
      "Precision [0.98961038961038961, 1.0]\n",
      "Recall [1.0, 0.9868852459016394]\n",
      "F_score [0.99477806788511747, 0.99339933993399332]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,Y,predictions_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"iris.data.txt\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "A = []\n",
    "B = []\n",
    "for i in r[0:150:\n",
    "    x = i.split(',')\n",
    "    A.append(map(float,x[0:len(x)-1]))\n",
    "    if x[-1] == \"Iris-setosa\\n\":\n",
    "        B.append([1])\n",
    "    elif x[-1] == 'Iris-versicolor\\n':\n",
    "        B.append([2])\n",
    "    elif x[-1] == 'Iris-virginica\\n':\n",
    "        B.append([3])\n",
    "ZA = deepcopy(A)\n",
    "ZA = np.array(create_data(ZA))\n",
    "A = np.array(A)\n",
    "B = np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes_B,class_count_B,alpha_B = find_alpha(B)\n",
    "multi_X_splitA =segregate_data(A,B,classes_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soft_theta = gradient_descent_soft(A,B,0.0001,0.0001,300,classes_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = predict_kclass(soft_theta,A,classes_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[50  0  0]\n",
      " [ 0 38 12]\n",
      " [ 0  0 50]]\n",
      "Accuracy 0.92\n",
      "Precision [1.0, 1.0, 0.80645161290322576]\n",
      "Recall [1.0, 0.76000000000000001, 1.0]\n",
      "F_score [1.0, 0.86363636363636365, 0.89285714285714279]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes_B,B,predict_kclass(soft_theta,A,classes_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.13333333]\n",
      "Fold 1 Testing Error [ 0.]\n",
      "Fold 2 Testing Error [ 0.13333333]\n",
      "Fold 3 Testing Error [ 0.06666667]\n",
      "Fold 4 Testing Error [ 0.06666667]\n",
      "Fold 5 Testing Error [ 0.06666667]\n",
      "Fold 6 Testing Error [ 0.2]\n",
      "Fold 7 Testing Error [ 0.06666667]\n",
      "Fold 8 Testing Error [ 0.06666667]\n",
      "Fold 9 Testing Error [ 0.4]\n",
      "Average Mean Square Error\n",
      "Training Error \t Testing Error\n",
      "0.107407407407 \t0.12\n"
     ]
    }
   ],
   "source": [
    "pre_rock, recall_rock,test_errork,conf_matk = cross_validation_kclass(A, B,classes_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0.88\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i in conf_matk:\n",
    "    acc.append(find_accuracy(i))\n",
    "print \"Mean Accuracy\", np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.2]\n",
      "Fold 1 Testing Error [ 0.]\n",
      "Fold 2 Testing Error [ 0.13333333]\n",
      "Fold 3 Testing Error [ 0.06666667]\n",
      "Fold 4 Testing Error [ 0.13333333]\n",
      "Fold 5 Testing Error [ 0.]\n",
      "Fold 6 Testing Error [ 0.33333333]\n",
      "Fold 7 Testing Error [ 0.]\n",
      "Fold 8 Testing Error [ 0.13333333]\n",
      "Fold 9 Testing Error [ 0.06666667]\n",
      "Average Mean Square Error\n",
      "Training Error \t Testing Error\n",
      "0.0962962962963 \t0.106666666667\n"
     ]
    }
   ],
   "source": [
    "pre_rock1, recall_rock1,test_errork1,conf_matk1 = cross_validation_kclass(ZA, B,classes_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy 0.893333333333\n"
     ]
    }
   ],
   "source": [
    "accz = []\n",
    "for i in conf_matk1:\n",
    "    accz.append(find_accuracy(i))\n",
    "print \"Mean Accuracy\", np.mean(accz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0]\n",
      " [0 3 3]\n",
      " [0 0 6]]\n",
      "[[4 0 0]\n",
      " [0 5 0]\n",
      " [0 0 6]]\n",
      "[[9 0 0]\n",
      " [0 2 2]\n",
      " [0 0 2]]\n",
      "[[6 0 0]\n",
      " [0 4 1]\n",
      " [0 0 4]]\n",
      "[[3 0 0]\n",
      " [0 4 2]\n",
      " [0 0 6]]\n",
      "[[4 0 0]\n",
      " [0 4 0]\n",
      " [0 0 7]]\n",
      "[[3 0 0]\n",
      " [0 3 5]\n",
      " [0 0 4]]\n",
      "[[7 0 0]\n",
      " [0 3 0]\n",
      " [0 0 5]]\n",
      "[[4 0 0]\n",
      " [0 4 2]\n",
      " [0 0 5]]\n",
      "[[7 0 0]\n",
      " [0 2 1]\n",
      " [0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "for i in conf_matk1:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 34, 16],\n",
       "       [ 0,  0, 50]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(conf_matk1,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
