{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log,factorial\n",
    "import re\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,f1_score\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"imdb_labelled.txt\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "review = []\n",
    "Y = []\n",
    "for i in r:\n",
    "    x = i.split('\\t')\n",
    "    review.append(x[0])\n",
    "    Y.append([int(x[-1])])\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = re.findall(r'\\w+', text.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def refine_words(reviews):\n",
    "    words = {}\n",
    "    for i in token_list:\n",
    "        for j in i:\n",
    "            if j not in words.keys():\n",
    "                words[j] = 1\n",
    "            else:\n",
    "                words[j] += 1\n",
    "    word_list = []\n",
    "    for i in words:\n",
    "        if words[i] < 25:\n",
    "            word_list.append(i)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_data(fw,tl):\n",
    "    data = []\n",
    "    for i in tl:\n",
    "        count = Counter(i)\n",
    "        tmp = [0]*len(fw)\n",
    "        for j in count:\n",
    "            if j in fw:\n",
    "                tmp[fw.index(j)] = count[j]\n",
    "        data.append(tmp)\n",
    "    return np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarizer(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] != 0:\n",
    "                data[i][j] = 1.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i[0] not in class_count1.keys():\n",
    "            class_count1[i[0]] = 1\n",
    "        else:\n",
    "            class_count1[i[0]] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate_data(data,labels,clabels):\n",
    "    multi_X = {}\n",
    "    for i in range(len(clabels)):\n",
    "        if clabels[i] not in multi_X.keys():\n",
    "            multi_X[clabels[i]] = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j][0] == clabels[i]:\n",
    "                multi_X[clabels[i]].append(data[j]) \n",
    "    for i in multi_X:\n",
    "        multi_X[i] = np.array(multi_X[i])\n",
    "    return multi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mean_multi(data):\n",
    "    multi_mean1 = {}\n",
    "    multi_s ={}\n",
    "    for i in data:\n",
    "        multi_mean1[i] = np.mean(data[i],axis =0)\n",
    "        multi_s[i] = np.sum(data[i],axis = 0)\n",
    "    return multi_s,multi_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothing(msum,sdata,sv):\n",
    "    smean = {}\n",
    "    for i in msum:\n",
    "        smean[i]= []\n",
    "        for j in range(len(msum[i])):\n",
    "            smean[i].append((msum[i][j]+sv)/float(np.sum(sdata[i])+2*sv))\n",
    "    for i in smean:\n",
    "        smean[i] = np.array(smean[i])\n",
    "    return smean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_covariance_multi(data_split,split_mean,n):\n",
    "    multi_intrim= {}\n",
    "    covar = {}\n",
    "    for i in data_split:\n",
    "        if i not in multi_intrim.keys():\n",
    "            multi_intrim[i] = []\n",
    "        for j in data_split[i]:\n",
    "            multi_intrim[i].append(j-split_mean[i])\n",
    "    for i in multi_intrim:\n",
    "        covar[i] = np.dot(np.array(multi_intrim[i]).transpose(),np.array(multi_intrim[i]))/float(n[i])\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(x,y,sv):\n",
    "    cl,n,alph = find_alpha(y)\n",
    "    data_seg = segregate_data(x,y,cl)\n",
    "    mean_s, mean_cl = find_mean_multi(data_seg)\n",
    "    sme = smoothing(mean_s,data_seg,sv)\n",
    "    return alph,sme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nCr(n,r):\n",
    "    return factorial(n) / factorial(r) /factorial(n-r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def membership_naive(data,mean,prior):\n",
    "    mem = []\n",
    "    P = np.sum(data)\n",
    "    for i in mean:\n",
    "        c = 0\n",
    "        for j in range(len(mean[i])):\n",
    "            comb = log(nCr(P,data[j]))\n",
    "            a = data[j]*log(mean[i][j])\n",
    "            b = (P-data[j])*log(1-mean[i][j])\n",
    "            c= c+a+b+comb\n",
    "        c = c+prior[i]\n",
    "        mem.append(c)\n",
    "    return mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determinist(data):\n",
    "    return data.index(max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_class(data,clabels):\n",
    "    return clabels[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(data,mean,prior,clabels):\n",
    "    member = []\n",
    "    for i in data:\n",
    "        member.append(membership_naive(i,mean,prior))\n",
    "    determine =[]\n",
    "    for j in member:\n",
    "        determine.append(determinist(j))\n",
    "    predict = [find_class(i,clabels) for i in determine]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squrae_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j][0] == i and actual[j][0] == predicted[j]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j][0] == i and actual[j][0] != predicted[j]:\n",
    "                tmp[clabels.index(predicted[j])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    precision = find_precision(confmatrix)\n",
    "    recall = find_recall(confmatrix)\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,sv,clabels, n_folds=10,MSE = False):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    accuracies = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_alpha,train_mean = training(data[train_ind], labels[train_ind],sv)\n",
    "        training_MSE = mean_squrae_error(prediction(data[train_ind],train_mean,train_alpha,clabels), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(data[test_ind],train_mean,train_alpha,clabels)\n",
    "        p,r = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "        accuracies.append(accuracy_score(labels[test_ind], predict))\n",
    "        \n",
    "    if MSE == True:\n",
    "        for i in range(len(testing_MSE_list)):\n",
    "            print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "        print \"Average Mean Square Error\"\n",
    "        print \"Training Error \\t Testing Error\"\n",
    "        print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    else:\n",
    "        for i in range(len(accuracies)):\n",
    "            print 'Fold',i,'Accuracy',accuracies[i]\n",
    "        print \"Average Accuracy \", np.mean(accuracies)\n",
    "    return precision_list,recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = []\n",
    "for i in review:\n",
    "    token_list.append(tokenize(i))\n",
    "final_words = refine_words(token_list)\n",
    "X = create_data(final_words,token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classses are [0, 1]\n",
      "The Classes Count  {0: 500, 1: 500}\n",
      "The prior probabiliy {0: 0.5, 1: 0.5}\n"
     ]
    }
   ],
   "source": [
    "classes,class_count,alpha = find_alpha(Y)\n",
    "print \"The Classses are\", classes\n",
    "print \"The Classes Count \", class_count\n",
    "print \"The prior probabiliy\", alpha\n",
    "multi_X_split =segregate_data(X,Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3859"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(multi_X_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed Mean for mulivariate features\n",
      "0 1.90925644917\n",
      "1 1.77596477596\n"
     ]
    }
   ],
   "source": [
    "multi_sum,multi_mean = find_mean_multi(multi_X_split)\n",
    "smoothing_value = 1\n",
    "smoothed_mean = smoothing(multi_sum,multi_X_split,smoothing_value)\n",
    "print \"Smoothed Mean for mulivariate features\"\n",
    "for i in smoothed_mean:\n",
    "    print i,np.sum(smoothed_mean[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value \t True Value \n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "0 \t\t\t[0]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n"
     ]
    }
   ],
   "source": [
    "a,m = training(X,Y,smoothing_value)\n",
    "predictions = prediction(X,m,a,classes)\n",
    "print \"Predicted Value \\t True Value \"\n",
    "for i in range(10,21):\n",
    "    print predictions[i],\"\\t\\t\\t\",Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy 0.76\n",
      "Fold 1 Accuracy 0.83\n",
      "Fold 2 Accuracy 0.77\n",
      "Fold 3 Accuracy 0.85\n",
      "Fold 4 Accuracy 0.76\n",
      "Fold 5 Accuracy 0.78\n",
      "Fold 6 Accuracy 0.77\n",
      "Fold 7 Accuracy 0.79\n",
      "Fold 8 Accuracy 0.77\n",
      "Fold 9 Accuracy 0.75\n",
      "Average Accuracy  0.783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.82499999999999996, 0.71666666666666667],\n",
       "  [0.89130434782608692, 0.77777777777777779],\n",
       "  [0.80000000000000004, 0.75],\n",
       "  [0.9285714285714286, 0.7931034482758621],\n",
       "  [0.84090909090909094, 0.6964285714285714],\n",
       "  [0.68421052631578949, 0.90697674418604646],\n",
       "  [0.83720930232558144, 0.7192982456140351],\n",
       "  [0.80434782608695654, 0.77777777777777779],\n",
       "  [0.80392156862745101, 0.73469387755102045],\n",
       "  [0.72916666666666663, 0.76923076923076927]],\n",
       " [[0.66000000000000003, 0.85999999999999999],\n",
       "  [0.77358490566037741, 0.8936170212765957],\n",
       "  [0.68085106382978722, 0.84905660377358494],\n",
       "  [0.76470588235294112, 0.93877551020408168],\n",
       "  [0.68518518518518523, 0.84782608695652173],\n",
       "  [0.90697674418604646, 0.68421052631578949],\n",
       "  [0.69230769230769229, 0.85416666666666663],\n",
       "  [0.75510204081632648, 0.82352941176470584],\n",
       "  [0.7592592592592593, 0.78260869565217395],\n",
       "  [0.74468085106382975, 0.75471698113207553]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X, Y,smoothing_value,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.22]\n",
      "Fold 1 Testing Error [ 0.17]\n",
      "Fold 2 Testing Error [ 0.16]\n",
      "Fold 3 Testing Error [ 0.21]\n",
      "Fold 4 Testing Error [ 0.17]\n",
      "Fold 5 Testing Error [ 0.26]\n",
      "Fold 6 Testing Error [ 0.25]\n",
      "Fold 7 Testing Error [ 0.22]\n",
      "Fold 8 Testing Error [ 0.26]\n",
      "Fold 9 Testing Error [ 0.18]\n",
      "Average Mean Square Error\n",
      "Training Error \t Testing Error\n",
      "0.0436666666667 \t0.21\n"
     ]
    }
   ],
   "source": [
    "cross_validation(X, Y, smoothing_value,classes,MSE = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[473  27]\n",
      " [ 16 484]]\n",
      "Accuracy 0.957\n",
      "Precision [0.96728016359918201, 0.94716242661448136]\n",
      "Recall [0.94599999999999995, 0.96799999999999997]\n",
      "F_score [0.95652173913043481, 0.95746785361028686]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
