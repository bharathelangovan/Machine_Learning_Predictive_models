{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7502eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from pylab import *\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist.data.shape\n",
    "mnist.target.shape\n",
    "np.unique(mnist.target)\n",
    "\n",
    "X, y = mnist.data / 255., mnist.target\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "size=len(y_train)\n",
    "\n",
    "## extract \"3\" digits and show their average\"\n",
    "ind = [ k for k in range(size) if y_train[k]==3 ]\n",
    "extracted_images=X_train[ind,:]\n",
    "\n",
    "mean_image=extracted_images.mean(axis=0)\n",
    "imshow(mean_image.reshape(28,28), cmap=cm.gray)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_data(data):\n",
    "    z = data\n",
    "    for j in z:\n",
    "        j.insert(0,1)   \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i not in class_count1.keys():\n",
    "            class_count1[i] = 1\n",
    "        else:\n",
    "            class_count1[i] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_high_dimension(Data,degree):\n",
    "    polyfeat_object = PolynomialFeatures(degree)\n",
    "    hd_data = polyfeat_object.fit_transform(Data)\n",
    "    return hd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate_data(data,labels,clabels):\n",
    "    multi_X = {}\n",
    "    for i in range(len(clabels)):\n",
    "        if clabels[i] not in multi_X.keys():\n",
    "            multi_X[clabels[i]] = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j][0] == clabels[i]:\n",
    "                multi_X[clabels[i]].append(data[j]) \n",
    "    for i in multi_X:\n",
    "        multi_X[i] = np.array(multi_X[i])\n",
    "    return multi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_sigmoid(theta,data):\n",
    "    sigmoid = []\n",
    "    for i in data:\n",
    "        x = np.dot(theta.transpose(),i)\n",
    "        sigmoid.append([1.0/(1+np.exp(-x))])\n",
    "    return np.array(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta_assume, learning_rate, interation_count):\n",
    "    theta = np.random.rand(len(x[0]))/10000\n",
    "    for i in range(interation_count):\n",
    "        h = find_sigmoid(theta,x)\n",
    "        new = learning_rate*(np.sum((h-y)*x,axis = 0))\n",
    "        theta = theta - new\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(theta,data):\n",
    "    sigmoid = find_sigmoid(theta,data)\n",
    "    predict = []\n",
    "    for i in sigmoid:\n",
    "        if i[0] > 0.5:\n",
    "            predict.append([1])\n",
    "        elif i[0] < 0.5:\n",
    "            predict.append([0])\n",
    "    return np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squrae_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j] == i and actual[j] == predicted[j][0]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j] == i and actual[j] != predicted[j][0]:\n",
    "                tmp[clabels.index(predicted[j][0])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    precision = find_precision(confmatrix)\n",
    "    recall = find_recall(confmatrix)\n",
    "    return precision,recall,confmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,clabels, n_folds=10,MSE = False):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    accuracies = []\n",
    "    precision_list = []\n",
    "    confusion = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_theta = gradient_descent(data[train_ind], labels[train_ind],0.0001,0.0001,300)\n",
    "        training_MSE = mean_squrae_error(prediction(train_theta,data[train_ind]), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(train_theta,data[test_ind])\n",
    "        p,r,cm = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        confusion.append(cm)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "        accuracies.append(accuracy_score(labels[test_ind], predict))\n",
    "        \n",
    "    if MSE == True:\n",
    "        for i in range(len(testing_MSE_list)):\n",
    "            print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "        print \"Average Mean Square Error\"\n",
    "        print \"Training Error \\t Testing Error\"\n",
    "        print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    else:\n",
    "        for i in range(len(accuracies)):\n",
    "            print 'Fold',i,'Accuracy',accuracies[i]\n",
    "        print \"Average Accuracy \", np.mean(accuracies)\n",
    "    return precision_list,recall_list,training_MSE_list,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(theta,data):\n",
    "    soft = {}\n",
    "    for i in data:\n",
    "        s = 0\n",
    "        for j in theta:\n",
    "            s = s + np.exp(np.dot(theta[j].transpose(),i))\n",
    "        for k in theta:\n",
    "            prodx = np.exp(np.dot(theta[k].transpose(),i))\n",
    "            if k not in soft.keys():\n",
    "                soft[k] = [[(prodx*1.0)/s]]\n",
    "            else:\n",
    "                soft[k].append([(prodx*1.0)/s])\n",
    "    return soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indicator(y,cl):\n",
    "    ind = {}\n",
    "    for k in cl:\n",
    "        for l in y:\n",
    "            if l == k:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[1]]\n",
    "                else:\n",
    "                    ind[k].append([1])\n",
    "            else:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[0]]\n",
    "                else:\n",
    "                    ind[k].append([0])\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pr(d,data):\n",
    "    data1 = []\n",
    "    for i in range(len(data)):\n",
    "        data1.append(d[i] * data[i])\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent_soft(x, y, theta_assume, learning_rate, interation_count,classes):\n",
    "    thetas = {}\n",
    "    theta = np.random.rand(len(classes),len(x[0]))/10000000\n",
    "    for i in classes:\n",
    "        thetas[i] = theta[int(i)]\n",
    "    indicators = indicator(y,classes)\n",
    "    for i in range(interation_count):\n",
    "        h = softmax(thetas,x)\n",
    "        for i in h:\n",
    "            d = np.array(h[i])-np.array(indicators[i])\n",
    "            d1 = pr(d,x)\n",
    "            sum1 = np.sum(d1,axis =0)                            \n",
    "            new = learning_rate*sum1\n",
    "            thetas[i] = thetas[i] - new\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_kclass(theta,data,cl):\n",
    "    pred = []\n",
    "    predi = []\n",
    "    for i in data:\n",
    "        tmp = []\n",
    "        for j in theta:\n",
    "            tmp.append((j,np.dot(theta[j].transpose(),i)))\n",
    "        pred.append(tmp)\n",
    "    for i in pred:\n",
    "        predi.append([max(i,key=lambda item:item[1])[0]])\n",
    "    return predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_kclass(data, labels,clabels, n_folds=10):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    precision_list = []\n",
    "    confusion = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_theta = gradient_descent_soft(data[train_ind], labels[train_ind],0.0000001,0.0001,300,clabels)\n",
    "        training_MSE = mean_squrae_error(predict_kclass(train_theta,data[train_ind],clabels), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = predict_kclass(train_theta,data[test_ind],clabels)\n",
    "        p,r,cm = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        confusion.append(cm)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "    for i in range(len(testing_MSE_list)):\n",
    "        print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "    print \"Average Mean Square Error\"\n",
    "    print \"Training Error \\t Testing Error\"\n",
    "    print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    return precision_list,recall_list,training_MSE_list,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Z= deepcopy(X_train)\n",
    "Z = create_data(Z)\"\"\"\n",
    "#Z = np.array(Z)\n",
    "\n",
    "classes,class_count,alpha = find_alpha(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soft_theta = gradient_descent_soft(X_train,y_train,0.0001,0.0001,300,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = predict_kclass(soft_theta,X_test,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 980    0    0    0    0    0    0    0    0    0]\n",
      " [1135    0    0    0    0    0    0    0    0    0]\n",
      " [1032    0    0    0    0    0    0    0    0    0]\n",
      " [1010    0    0    0    0    0    0    0    0    0]\n",
      " [ 982    0    0    0    0    0    0    0    0    0]\n",
      " [ 892    0    0    0    0    0    0    0    0    0]\n",
      " [ 958    0    0    0    0    0    0    0    0    0]\n",
      " [1028    0    0    0    0    0    0    0    0    0]\n",
      " [ 974    0    0    0    0    0    0    0    0    0]\n",
      " [1009    0    0    0    0    0    0    0    0    0]]\n",
      "Accuracy 0.098\n",
      "Precision [0.098000000000000004, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Recall [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "F_score [0.1785063752276867, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:7: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,y_test,xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:100][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cld = {}\n",
    "for i in range(len(y_train)):\n",
    "    if y[i] not in cld.keys():\n",
    "        cld[y[i]] = [i]\n",
    "    else:\n",
    "        cld[y[i]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cld1= {}\n",
    "for i in cld:\n",
    "    cld1[i] = (min(cld[i]),max(cld[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_new = []\n",
    "y_new = []\n",
    "for i in cld1:\n",
    "    x=cld1[i][0]+1000\n",
    "    y = cld1[i][0]+1100\n",
    "    for l in range(x,y):\n",
    "        X_new.append(X_train[l])\n",
    "        y_new.append(y_train[l])\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soft_theta1 = gradient_descent_soft(X_new,y_new,0.0001,0.0001,300,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx1 = predict_kclass(soft_theta1,X_test,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 942    0    2    2    0    6   18    1    9    0]\n",
      " [   0 1063   14    3    1    6    4    0   44    0]\n",
      " [  30   21  823   26   17    2   41   24   41    7]\n",
      " [   7    1   31  856    1   35   10   14   33   22]\n",
      " [   6    9    4    0  858    1   18    2   11   73]\n",
      " [  26    2    1   89   20  648   36   11   46   13]\n",
      " [  16    3   12    1   20   12  888    1    5    0]\n",
      " [   6   31   48    1   14    0    0  887    7   34]\n",
      " [  11   19    8   37   17   26   17   18  800   21]\n",
      " [  22   12   12   10   55   12    3   36   11  836]]\n",
      "Accuracy 0.8601\n",
      "Precision [0.8836772983114447, 0.91559000861326445, 0.86178010471204192, 0.83512195121951216, 0.85543369890329013, 0.86631016042780751, 0.85797101449275359, 0.89235412474849096, 0.79443892750744782, 0.83101391650099399]\n",
      "Recall [0.96122448979591835, 0.93656387665198237, 0.79748062015503873, 0.8475247524752475, 0.87372708757637474, 0.726457399103139, 0.92693110647181631, 0.86284046692607008, 0.82135523613963035, 0.82854311199207131]\n",
      "F_score [0.92082111436950154, 0.9259581881533101, 0.82838449924509305, 0.84127764127764126, 0.86448362720403027, 0.79024390243902443, 0.89111891620672357, 0.87734915924826906, 0.80767289247854612, 0.82977667493796525]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,y_test,xx1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
