{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log ,factorial\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,f1_score\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"spambase.data\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "X = []\n",
    "Y = []\n",
    "for i in r:\n",
    "    x = i.split(',')\n",
    "    X.append(map(float,x[1:len(x)-1]))\n",
    "    Y.append([int(x[-1])])\n",
    "Y = np.array(Y)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def binarizer(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] != 0:\n",
    "                data[i][j] = 1.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i[0] not in class_count1.keys():\n",
    "            class_count1[i[0]] = 1\n",
    "        else:\n",
    "            class_count1[i[0]] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate_data(data,labels,clabels):\n",
    "    multi_X = {}\n",
    "    for i in range(len(clabels)):\n",
    "        if clabels[i] not in multi_X.keys():\n",
    "            multi_X[clabels[i]] = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j][0] == clabels[i]:\n",
    "                multi_X[clabels[i]].append(data[j]) \n",
    "    for i in multi_X:\n",
    "        multi_X[i] = np.array(multi_X[i])\n",
    "    return multi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_mean_multi(data):\n",
    "    multi_mean1 = {}\n",
    "    multi_s ={}\n",
    "    for i in data:\n",
    "        multi_mean1[i] = np.mean(data[i],axis =0)\n",
    "        multi_s[i] = np.sum(data[i],axis = 0)\n",
    "    return multi_s,multi_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothing(msum,sdata,sv):\n",
    "    smean = {}\n",
    "    for i in msum:\n",
    "        smean[i]= []\n",
    "        for j in range(len(msum[i])):\n",
    "            smean[i].append(float(msum[i][j]+sv)/(len(sdata[i])+2*sv))\n",
    "    for i in smean:\n",
    "        smean[i] = np.array(smean[i])\n",
    "    return smean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_covariance_multi(data_split,split_mean,n):\n",
    "    multi_intrim= {}\n",
    "    covar = {}\n",
    "    for i in data_split:\n",
    "        if i not in multi_intrim.keys():\n",
    "            multi_intrim[i] = []\n",
    "        for j in data_split[i]:\n",
    "            multi_intrim[i].append(j-split_mean[i])\n",
    "    for i in multi_intrim:\n",
    "        covar[i] = np.dot(np.array(multi_intrim[i]).transpose(),np.array(multi_intrim[i]))/float(n[i])\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(x,y,sv):\n",
    "    cl,n,alph = find_alpha(y)\n",
    "    data_seg = segregate_data(x,y,cl)\n",
    "    mean_s, mean_cl = find_mean_multi(data_seg)\n",
    "    sme = smoothing(mean_s,data_seg,sv)\n",
    "    return alph,sme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def membership_naive(data,mean,prior):\n",
    "    mem = []\n",
    "    for i in mean:\n",
    "        c = 0\n",
    "        for j in range(len(mean[i])):\n",
    "            if data[j] == 1:\n",
    "                a = log(mean[i][j])\n",
    "            elif data[j] == 0:\n",
    "                a = log(1-mean[i][j])   \n",
    "            c= c+a\n",
    "        c = c+prior[i]\n",
    "        mem.append(c)\n",
    "    return mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determinist(data):\n",
    "    return data.index(max(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_class(data,clabels):\n",
    "    return clabels[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(data,mean,prior,clabels):\n",
    "    member = []\n",
    "    for i in data:\n",
    "        member.append(membership_naive(i,mean,prior))\n",
    "    determine =[]\n",
    "    for j in member:\n",
    "        determine.append(determinist(j))\n",
    "    predict = [find_class(i,clabels) for i in determine]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squrae_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j][0] == i and actual[j][0] == predicted[j]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j][0] == i and actual[j][0] != predicted[j]:\n",
    "                tmp[clabels.index(predicted[j])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    precision = find_precision(confmatrix)\n",
    "    recall = find_recall(confmatrix)\n",
    "    return precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,sv,clabels, n_folds=10,MSE = False):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    accuracies = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_alpha,train_mean = training(data[train_ind], labels[train_ind],sv)\n",
    "        training_MSE = mean_squrae_error(prediction(data[train_ind],train_mean,train_alpha,clabels), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(data[test_ind],train_mean,train_alpha,clabels)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "        accuracies.append(accuracy_score(labels[test_ind], predict))\n",
    "        \n",
    "    if MSE == True:\n",
    "        for i in range(len(testing_MSE_list)):\n",
    "            print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "        print \"Average Mean Square Error\"\n",
    "        print \"Training Error \\t Testing Error\"\n",
    "        print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    else:\n",
    "        for i in range(len(accuracies)):\n",
    "            print 'Fold',i,'Accuracy',accuracies[i]\n",
    "        print \"Average Accuracy \", np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,sv,clabels, n_folds=10,MSE = False):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    accuracies = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_alpha,train_mean = training(data[train_ind], labels[train_ind],sv)\n",
    "        training_MSE = mean_squrae_error(prediction(data[train_ind],train_mean,train_alpha,clabels), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(data[test_ind],train_mean,train_alpha,clabels)\n",
    "        p,r = roc(clabels,labels[test_ind],predict)\n",
    "        precision_list.append(p)\n",
    "        recall_list.append(r)\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "        accuracies.append(accuracy_score(labels[test_ind], predict))\n",
    "        \n",
    "    if MSE == True:\n",
    "        for i in range(len(testing_MSE_list)):\n",
    "            print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "        print \"Average Mean Square Error\"\n",
    "        print \"Training Error \\t Testing Error\"\n",
    "        print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    else:\n",
    "        for i in range(len(accuracies)):\n",
    "            print 'Fold',i,'Accuracy',accuracies[i]\n",
    "        print \"Average Accuracy \", np.mean(accuracies)\n",
    "    return precision_list,recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = binarizer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classses are [0, 1]\n",
      "The Classes Count  {0: 2788, 1: 1813}\n",
      "The prior probabiliy {0: 0.6059552271245382, 1: 0.39404477287546186}\n"
     ]
    }
   ],
   "source": [
    "classes,class_count,alpha = find_alpha(Y)\n",
    "print \"The Classses are\", classes\n",
    "print \"The Classes Count \", class_count\n",
    "print \"The prior probabiliy\", alpha\n",
    "multi_X_split =segregate_data(X,Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothed Mean for mulivariate features\n",
      "0 [ 0.09820789  0.27741935  0.00322581  0.22043011  0.11433692  0.01577061\n",
      "  0.07383513  0.07849462  0.17060932  0.05125448  0.42401434  0.11935484\n",
      "  0.04551971  0.01792115  0.090681    0.09569892  0.12580645  0.58064516\n",
      "  0.0172043   0.34336918  0.00824373  0.02795699  0.01971326  0.37311828\n",
      "  0.28136201  0.27706093  0.15555556  0.12939068  0.16200717  0.10430108\n",
      "  0.07311828  0.12365591  0.07383513  0.15770609  0.17491039  0.26129032\n",
      "  0.01863799  0.11577061  0.09032258  0.05304659  0.11541219  0.10430108\n",
      "  0.10071685  0.29569892  0.16129032  0.01612903  0.06738351  0.18637993\n",
      "  0.5516129   0.14336918  0.26810036  0.1046595   0.08243728  0.99964158\n",
      "  0.99964158  0.99964158]\n",
      "1 [ 0.34490358  0.61487603  0.02203857  0.62534435  0.37575758  0.4214876\n",
      "  0.3415978   0.30633609  0.45619835  0.31294766  0.63030303  0.28705234\n",
      "  0.12782369  0.15867769  0.54545455  0.384573    0.37961433  0.88650138\n",
      "  0.20826446  0.80826446  0.05289256  0.3322314   0.37575758  0.02809917\n",
      "  0.015427    0.00495868  0.01707989  0.00716253  0.01046832  0.00220386\n",
      "  0.00165289  0.03415978  0.00606061  0.02589532  0.06225895  0.05619835\n",
      "  0.01818182  0.03471074  0.11184573  0.00110193  0.01157025  0.04738292\n",
      "  0.02644628  0.26887052  0.03801653  0.01101928  0.00936639  0.14986226\n",
      "  0.64903581  0.07217631  0.83305785  0.61157025  0.28760331  0.99944904\n",
      "  0.99944904  0.99944904]\n"
     ]
    }
   ],
   "source": [
    "multi_sum,multi_mean = find_mean_multi(multi_X_split)\n",
    "smoothing_value = 1\n",
    "smoothed_mean = smoothing(multi_sum,multi_X_split,smoothing_value)\n",
    "print \"Smoothed Mean for mulivariate features\"\n",
    "for i in smoothed_mean:\n",
    "    print i,smoothed_mean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value \t True Value \n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "0 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "1 \t\t\t[1]\n",
      "0 \t\t\t[1]\n"
     ]
    }
   ],
   "source": [
    "a,m = training(X,Y,smoothing_value)\n",
    "predictions = prediction(X,m,a,classes)\n",
    "print \"Predicted Value \\t True Value \"\n",
    "for i in range(10,21):\n",
    "    print predictions[i],\"\\t\\t\\t\",Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy 0.889370932755\n",
      "Fold 1 Accuracy 0.89347826087\n",
      "Fold 2 Accuracy 0.90652173913\n",
      "Fold 3 Accuracy 0.889130434783\n",
      "Fold 4 Accuracy 0.889130434783\n",
      "Fold 5 Accuracy 0.880434782609\n",
      "Fold 6 Accuracy 0.913043478261\n",
      "Fold 7 Accuracy 0.882608695652\n",
      "Fold 8 Accuracy 0.886956521739\n",
      "Fold 9 Accuracy 0.865217391304\n",
      "Average Accuracy  0.889589267189\n"
     ]
    }
   ],
   "source": [
    "cross_validation(X, Y,smoothing_value,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.11930586]\n",
      "Fold 1 Testing Error [ 0.09782609]\n",
      "Fold 2 Testing Error [ 0.09782609]\n",
      "Fold 3 Testing Error [ 0.1]\n",
      "Fold 4 Testing Error [ 0.10434783]\n",
      "Fold 5 Testing Error [ 0.11956522]\n",
      "Fold 6 Testing Error [ 0.12391304]\n",
      "Fold 7 Testing Error [ 0.12173913]\n",
      "Fold 8 Testing Error [ 0.11086957]\n",
      "Fold 9 Testing Error [ 0.11304348]\n",
      "Average Mean Square Error\n",
      "Training Error \t Testing Error\n",
      "0.110120977103 \t0.110843629162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.85858585858585856, 0.92073170731707321],\n",
       "  [0.90666666666666662, 0.89375000000000004],\n",
       "  [0.91078066914498146, 0.89005235602094246],\n",
       "  [0.88513513513513509, 0.92682926829268297],\n",
       "  [0.90969899665551834, 0.86956521739130432],\n",
       "  [0.88235294117647056, 0.87765957446808507],\n",
       "  [0.89198606271777003, 0.8497109826589595],\n",
       "  [0.8896551724137931, 0.85882352941176465],\n",
       "  [0.89456869009584661, 0.87755102040816324],\n",
       "  [0.89323843416370108, 0.87709497206703912]],\n",
       " [[0.95149253731343286, 0.78238341968911918],\n",
       "  [0.94117647058823528, 0.83625730994152048],\n",
       "  [0.92105263157894735, 0.87628865979381443],\n",
       "  [0.95620437956204385, 0.81720430107526887],\n",
       "  [0.92832764505119458, 0.83832335329341312],\n",
       "  [0.9125475285171103, 0.8375634517766497],\n",
       "  [0.90780141843971629, 0.8258426966292135],\n",
       "  [0.91489361702127658, 0.8202247191011236],\n",
       "  [0.93959731543624159, 0.79629629629629628],\n",
       "  [0.91941391941391937, 0.83957219251336901]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation(X, Y, smoothing_value,classes,MSE = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2594  194]\n",
      " [ 314 1499]]\n",
      "Accuracy 0.889589219735\n",
      "Precision [0.89202200825309486, 0.88541051388068515]\n",
      "Recall [0.93041606886657102, 0.82680639823496971]\n",
      "F_score [0.91081460674157311, 0.85510553337136341]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
