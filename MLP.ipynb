{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from sklearn.cross_validation import KFold,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,recall_score,f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data(data):\n",
    "    z = data\n",
    "    for j in z:\n",
    "        j.insert(0,1)   \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_alpha(class_labels):\n",
    "    alpha1 = {}\n",
    "    class_count1 = {}\n",
    "    for i in class_labels:\n",
    "        if i[0] not in class_count1.keys():\n",
    "            class_count1[i[0]] = 1\n",
    "        else:\n",
    "            class_count1[i[0]] += 1\n",
    "    classes1 = class_count1.keys()\n",
    "    for j in  class_count1:\n",
    "        alpha1[j] = class_count1[j]*1.0/len(class_labels)\n",
    "    return classes1,class_count1,alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segregate_data(data,labels,clabels):\n",
    "    multi_X = {}\n",
    "    for i in range(len(clabels)):\n",
    "        if clabels[i] not in multi_X.keys():\n",
    "            multi_X[clabels[i]] = []\n",
    "        for j in range(len(labels)):\n",
    "            if labels[j][0] == clabels[i]:\n",
    "                multi_X[clabels[i]].append(data[j]) \n",
    "    for i in multi_X:\n",
    "        multi_X[i] = np.array(multi_X[i])\n",
    "    return multi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assume_weight(h,x):\n",
    "    w = {}\n",
    "    th = np.random.rand(h,len(x[0]))/10000\n",
    "    #th = ((th-np.sum(th,axis =0))/np.sum(th,axis =0))/10000\n",
    "    \"\"\"th = th/(20000*np.sum(th))\n",
    "    print th    \"\"\"\n",
    "    for i in range(h):\n",
    "        w[i] = th[i]\n",
    "    return w      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assume_V(cl,h):\n",
    "    v= {}\n",
    "    th = np.random.rand(len(cl),h)/10000\n",
    "    #th = ((th-np.sum(th,axis =0))/np.sum(th,axis =0))/100000000\n",
    "    #th = th/(20000*np.sum(th))\n",
    "    for i in cl:\n",
    "        v[i] = th[i-1]\n",
    "    return v      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indicator(y,cl):\n",
    "    ind = {}\n",
    "    for k in cl:\n",
    "        for l in y:\n",
    "            if l[0] == k:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[1]]\n",
    "                else:\n",
    "                    ind[k].append([1])\n",
    "            else:\n",
    "                if k not in ind.keys():\n",
    "                    ind[k] = [[0]]\n",
    "                else:\n",
    "                    ind[k].append([0])\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_sigmoid1(w,data):\n",
    "    sigmoid = []\n",
    "    for i in data:\n",
    "        tmp = []\n",
    "        for j in w:\n",
    "            x = np.dot(w[j].transpose(),i)\n",
    "            tmp.append(1.0/(1+np.exp(-x)))\n",
    "        sigmoid.append(tmp)\n",
    "    sigmoig =create_data(sigmoid)\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_sigmoid(w,data):\n",
    "    sigmoid = {}\n",
    "    for i in w:\n",
    "        tmp = []\n",
    "        for j in data:\n",
    "            x = np.dot(w[i].transpose(),j)\n",
    "            tmp.append([1.0/(1+np.exp(-x))])\n",
    "        sigmoid[i] = np.array(tmp)\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax(theta,data):\n",
    "    soft = {}\n",
    "    for i in data:\n",
    "        s = 0\n",
    "        for j in theta:\n",
    "            s = s + np.exp(np.dot(theta[j].transpose(),i))\n",
    "        for k in theta:\n",
    "            x = np.exp(np.dot(theta[k].transpose(),i))\n",
    "            if k not in soft.keys():\n",
    "                soft[k] = [[(x*1.0)/s]]\n",
    "            else:\n",
    "                soft[k].append([(x*1.0)/s])\n",
    "    for i in soft:\n",
    "        soft[i] = np.array(soft[i])\n",
    "    return soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intrim(yh,y,v,j,k):\n",
    "    s = 0\n",
    "    for i in v:\n",
    "        x = yh[i][k]- y[i][k]\n",
    "        s = s + x*v[i][j]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grad_desc(W,V,data,indic,lr,ic):\n",
    "    for cnt in range(ic):\n",
    "        zy = find_sigmoid1(W,data)\n",
    "        zz = find_sigmoid(W,data)\n",
    "        yhat = softmax(V,zy)\n",
    "        for m in yhat:\n",
    "            x = yhat[m] - indic[m]\n",
    "            xz = x*zy\n",
    "            V[m] = V[m] - (lr*np.sum(xz,axis=0))\n",
    "        for j in W:\n",
    "            s = 0\n",
    "            for i in range(len(data)):\n",
    "                s = s + intrim(yhat,indic,V,j,i)*zy[i][j]*(1-zy[i][j])*data[i]\n",
    "            W[j] = W[j] - (lr*s)\n",
    "    return V,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_desc_m(W,V,data,indic,lr,ic):\n",
    "    prevw = {}\n",
    "    for cnt in range(ic):\n",
    "        zy = find_sigmoid1(W,data)\n",
    "        zz = find_sigmoid(W,data)\n",
    "        yhat = softmax(V,zy)\n",
    "        for m in yhat:\n",
    "            x = yhat[m] - indic[m]\n",
    "            xz = x*zy\n",
    "            V[m] = V[m] - (lr*np.sum(xz,axis=0))\n",
    "        prevw[cnt] = W\n",
    "        for j in W:\n",
    "            s = 0\n",
    "            for i in range(X.shape[0]):\n",
    "                print i\n",
    "                s = s + intrim(yhat,indic,V,j,i)*zy[j][i]*(1-zy[j][i])*data[i]\n",
    "            if cnt != 0:\n",
    "                W[j] = W[j] - (lr*s) + (0.2*prevw[cnt-1][j])\n",
    "    return V,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prediction(w,v,data):\n",
    "    Zp = find_sigmoid1(w,data)\n",
    "    pre = softmax(v,Zp)  \n",
    "    ll = []\n",
    "    for j in range(len(pre.values()[0])):\n",
    "        tmp= []\n",
    "        for i in pre:\n",
    "            tmp.append((i,pre[i][j][0]))\n",
    "        ll.append(tmp)\n",
    "    predi =[]\n",
    "    for i in ll:\n",
    "            predi.append([max(i,key=lambda item:item[1])[0]])\n",
    "    return np.array(predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squrae_error(pred,y):\n",
    "    return sum([(i-j)**2 for i,j in zip(pred,y)])/float(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_confusion_matrix(clabels,actual,predicted):\n",
    "    cm= []\n",
    "    for i in clabels:\n",
    "        tmp =[0]*len(clabels)\n",
    "        for j in range(len(actual)):\n",
    "            if actual[j][0] == i and actual[j][0] == predicted[j][0]:\n",
    "                tmp[clabels.index(i)] += 1\n",
    "            elif actual[j][0] == i and actual[j][0] != predicted[j][0]:\n",
    "                tmp[clabels.index(predicted[j][0])] += 1\n",
    "        cm.append(tmp)\n",
    "    return np.array(cm)\n",
    "def find_accuracy(matrix):\n",
    "    return np.trace(matrix)*1.0/np.sum(matrix)\n",
    "def find_precision(matrix):\n",
    "    pres = []\n",
    "    x = np.sum(matrix,axis=0)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                pres.append(matrix[i][j]*1.0/x[i])\n",
    "    return pres\n",
    "def find_recall(matrix):\n",
    "    rec = []\n",
    "    x = np.sum(matrix,axis=1)\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i == j:\n",
    "                rec.append(matrix[i][j]*1.0/x[i])\n",
    "    return rec\n",
    "def find_fmeasure(prec,rec):\n",
    "    tmp = []\n",
    "    for i,j in zip(prec,rec):\n",
    "        tmp.append(2.0*(i*j)/(i+j))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roc(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    precision = find_precision(confmatrix)\n",
    "    recall = find_recall(confmatrix)\n",
    "    return precision,recall,confmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation(data, labels,clabels, n_folds=10):\n",
    "    cv = KFold(len(labels), n_folds,shuffle= True)\n",
    "    precision_list = []\n",
    "    confusion = []\n",
    "    recall_list = []\n",
    "    training_MSE_list =[]\n",
    "    testing_MSE_list = []\n",
    "    i = 0\n",
    "    for train_ind, test_ind in cv: \n",
    "        train_V,train_W = training(data[train_ind], labels[train_ind],4,clabels,0.000454,1000)\n",
    "        training_MSE = mean_squrae_error(prediction(train_W,train_V,data[train_ind]), labels[train_ind])\n",
    "        training_MSE_list.append(training_MSE)\n",
    "        predict = prediction(train_W,train_V,data[test_ind])\n",
    "        #p,r,cm = roc(clabels,labels[test_ind],predict)\n",
    "        #precision_list.append(p)\n",
    "        #recall_list.append(r)\n",
    "        confusion.append(find_confusion_matrix(clabels,labels[test_ind],predict))\n",
    "        testing_MSE_list.append(mean_squrae_error(predict,labels[test_ind]))\n",
    "    for i in range(len(testing_MSE_list)):\n",
    "        print 'Fold',i,'Testing Error',testing_MSE_list[i]\n",
    "    print \"Average Mean Square Error\"\n",
    "    print \"Training Error \\t Testing Error\"\n",
    "    print np.mean(training_MSE_list),\"\\t\",np.mean(testing_MSE_list)\n",
    "    return training_MSE_list,confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(clabels,acutal,predicted):\n",
    "    confmatrix = find_confusion_matrix(clabels,acutal,predicted)\n",
    "    print \"Confusion Matrix\"\n",
    "    print confmatrix\n",
    "    accuracy = find_accuracy(confmatrix)\n",
    "    print \"Accuracy\", accuracy\n",
    "    precision = find_precision(confmatrix)\n",
    "    print \"Precision\", precision\n",
    "    recall = find_recall(confmatrix)\n",
    "    print \"Recall\", recall\n",
    "    f_score =find_fmeasure(precision,recall)\n",
    "    print \"F_score\", f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"iris.data.txt\"\n",
    "r = io.open(filename, encoding='utf8').readlines()\n",
    "X = []\n",
    "Y = []\n",
    "for i in r[0:150]:\n",
    "    x = i.split(',')\n",
    "    X.append(map(float,x[0:len(x)-1]))\n",
    "    if x[-1] == \"Iris-setosa\\n\":\n",
    "        Y.append([1])\n",
    "    elif x[-1] == 'Iris-versicolor\\n':\n",
    "        Y.append([2])\n",
    "    elif x[-1] == 'Iris-virginica\\n':\n",
    "        Y.append([3])\n",
    "ZX = deepcopy(X)\n",
    "ZX = np.array(create_data(ZX))\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes,class_count,alpha = find_alpha(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(data,y,h,cl,lr,ic):\n",
    "    W0 = assume_weight(h,ZX)\n",
    "    V0 = assume_V(classes,(h+1))\n",
    "    ind = indicator(y,cl)\n",
    "    Vf,Wf = grad_desc(W0,V0,data,ind,lr,ic)\n",
    "    return Vf,Wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V,W = training(ZX,Y,4,classes,0.00000000454,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = prediction(W,V,ZX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ZX, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes,class_count,alpha = find_alpha(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V,W = training(X_train,y_train,4,classes,0.00454,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = prediction(W,V,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[23  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 18]]\n",
      "Accuracy 0.983333333333\n",
      "Precision [1.0, 1.0, 0.94736842105263153]\n",
      "Recall [1.0, 0.94736842105263153, 1.0]\n",
      "F_score [1.0, 0.97297297297297303, 0.97297297297297303]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,y_test,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Testing Error [ 0.4]\n",
      "Fold 1 Testing Error [ 0.4]\n",
      "Fold 2 Testing Error [ 0.2]\n",
      "Fold 3 Testing Error [ 0.46666667]\n",
      "Fold 4 Testing Error [ 0.]\n",
      "Fold 5 Testing Error [ 0.33333333]\n",
      "Fold 6 Testing Error [ 0.53333333]\n",
      "Fold 7 Testing Error [ 0.4]\n",
      "Fold 8 Testing Error [ 0.33333333]\n",
      "Fold 9 Testing Error [ 0.4]\n",
      "Average Mean Square Error\n",
      "Training Error \t Testing Error\n",
      "0.317037037037 \t0.346666666667\n"
     ]
    }
   ],
   "source": [
    "mse,cmatrix = cross_validation(ZX,Y,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5. ,  0. ,  0. ],\n",
       "       [ 0.2,  1.2,  3.6],\n",
       "       [ 0. ,  1.4,  3.6]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cmatrix,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V1,W1 = training(X_train,y_train,5,classes,0.00454,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P1 = prediction(W1,V1,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[23  0  0]\n",
      " [ 0  5 14]\n",
      " [ 0  0 18]]\n",
      "Accuracy 0.766666666667\n",
      "Precision [1.0, 1.0, 0.5625]\n",
      "Recall [1.0, 0.26315789473684209, 1.0]\n",
      "F_score [1.0, 0.41666666666666669, 0.71999999999999997]\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,y_test,P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V2,W2 = training(X_train,y_train,2,classes,0.000000000004954,110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P2 = prediction(W2,V2,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 0  0 23]\n",
      " [ 0  0 19]\n",
      " [ 0  0 18]]\n",
      "Accuracy 0.3\n",
      "Precision [nan, nan, 0.29999999999999999]\n",
      "Recall [0.0, 0.0, 1.0]\n",
      "F_score [nan, nan, 0.46153846153846151]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel\\__main__.py:20: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "evaluation(classes,y_test,P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[23  0  0]\n",
      " [ 0 12  7]\n",
      " [ 0  0 18]]\n",
      "Accuracy 0.883333333333\n",
      "Precision [1.0, 1.0, 0.71999999999999997]\n",
      "Recall [1.0, 0.63157894736842102, 1.0]\n",
      "F_score [1.0, 0.77419354838709675, 0.83720930232558133]\n"
     ]
    }
   ],
   "source": [
    "V3,W3 = training(X_train,y_train,8,classes,0.00454,500)\n",
    "P3 = prediction(W3,V3,X_test)\n",
    "evaluation(classes,y_test,P3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
